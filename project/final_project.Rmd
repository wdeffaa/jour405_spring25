---
title: "final_project"
output: html_document
---

```{r}
library(tidyverse)
```

Tests I would Like to Run:

For my final project, the main hypothesis I would like to test is that Rotten Tomatoes ratings, given by movie critics, are often indicative of public opinion. I believe the one way to test this hypothesis is by using the ANOVA test to see if there are similar patterns in high reviews given by movie critics via Rotten Tomatoes ratings, to high reviews given by public opinion via Letterboxd ratings, or if similar patterns do not exist. Another way that I could test this would be to use the 'cor()' function to calculate the possible correlation between high reviews given by critics and high reviews given via public opinion. While I believe these are good ways to test this hypothesis, I still feel there are better ways to test, but I am unsure what other tests may sute this task better. 

For my second hypothesis, I would like to look into critical and public perception of movies based on how old they are. My hypothesis is that movie critics (Rotten Tomatoes) are more favorable to older movies in terms of ratings and that public opinion (Letterboxd), are more favorable to newer movies. I would use the same tests I used for my first hypothesis for this one as well. My main concern for this hypothesis is I am not too sure how to label some movies as 'new' and some as 'old'. My first thought was to consider movies made before 1980 'old' and movies after this year to be 'new'. I would love to have your opinion on this matter as I am still unsure if this is the best line to draw between 'new' and 'old'.         

```{r}
read_csv("Movie_Reviews.csv")
```
The data listed is films from the IMDb Top 250 Movies list, numbered from 1-250. The dataset contains the title of the movie, the year released, the Rotten Tomatoes rating, the adjusted Rotten Tomatoes rating and the Letterboxd rating for each movie. For the adjusted Rotten Tomatoes rating, I used the formula (RT_Rating / 100) * 5 * 100. Some numbers came back with decimal places that went to the hundredth, to fix this to make sure every number just went to the tenth, numbers that were 5 and above in the hundredth place would be rounded up to the nearest tenth decimal place, and numbers 4 and below would be rounded down to the nearest tenth decimal place. One issue I encountered with a few films was some numbers coming out as 4.95, to fix this, I determined that if the Rotten Tomatoes rating was NOT 100%, I did NOT round up and instead simply put the value at 4.9. In the right-most column, I put the Letterboxd rating for each movie by looking through the Letterboxd app and going through every movie, checking their ratings. The time period of these movies range from 1921-2024, with the oldest movie being "The Kid" (1921), and the newest movies being "Dune: Part Two," "The Wild Robot," "I'm Still Here" and "Maharaja" (2024). Something that is missing and that I may want to cover to make sure I have the most accurate data is listing the number of reviewers for these movies. When listing movies, I noticed that some movies have a much higher amount of reviews than others. I am concerned that this imbalance can skew the data and possibly make it less reliable. What is the best way for me to level out the playing field for the amount of reviews these movies have? This is a concern I have for both Rotten Tomatoes and Letterboxd reviews. One final idea I have that I would like to examine is do Rotten Tomatoes reviewers (critics) rate older movies more favorably than newer movies, and vice versa. This is a question I have regarding Letterboxd reviewers (public opinion) as well.  
